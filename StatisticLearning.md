## 2.2. Empirical Risk Minimization（经验风险最小化）

**定义**
$S$ 是一个从全体数据集中采样得到的一个训练集；
$\mathcal{D}$ 是采集训练集 $S$ 时所服从的一种未知的分布；
$f$ 是一个目标函数，给训练集中的每个样本打上标签；
$h_S: \mathcal{X} \rarr \mathcal{Y}$ 是一个预测函数，这个函数用来预测给定输入 $\mathcal{X}$ 到输出 $\mathcal{Y}$；

算法目标：找到一个 $h_S$ 能够最接近的表示这个未知的分布 $\mathcal{D}$ 和函数 $f$；

$L_S(h)$ 表示预测函数和实际情况的误差。但是我们并不知道实际上这个未知的分布 $\mathcal{D}$ 和函数 $f$ 到底是多少，因此我们只能计算预测函数和训练集的偏差：
$$
L_S(h) \stackrel{\text{def}}{=} \frac{|\{i \in [m]:h(x_i)\ne y_i \}|}{m}, [m] = \{1, \ldots, m\}
$$

**empirical error** 或 **empirical risk** 指的就是这个 $L_S(h)$。

**Empirical Risk Minimization, ERM** ：通过使得经验风险 $L_S(h)$ 最小，而找到的一个预测函数 $h_S$ 的这个学习范式被称为经验风险最小。

**解释**
我们所处的这个世界上任何一项活动所产生的所有数据 $T$，是没有办法全部收集到的。在这种情况下，我们只能收集到一些有限的数据 $S$，同时也从实际环境中收集到了这些数据对应的标签 $L$。

但我们并不知道这些收集到的数据 $S$ 在实际的数据集 $T$ 中的分布 $\mathcal{D}$ 是如何的，并且我们也不知道从 $S$ 到 $L$ 的这个关系 $f$ 是如何的。

所以我们只能去猜测某种关系 $h_S$，用这个关系去近似的表示数据集 $S$ 到 $L$ 的关系，用 $L_S(h)$ 来表示关系 $h_S$ 和实际 $S$ 到 $L$ 关系的误差，通过使得这个误差最小，就能够找到一个能够对这些数据进行预测的函数。

这种寻找这个预测函数的学习范式被称为经验风险最小化。

### 2.2.1. overfittting（过拟合）
当 $L_S(h)$ 在数据集 $S$ 上非常小，$h_S$ 在 $S$ 上表现的非常好。但是在对不属于训练集中的数据预测时效果很差，这种情况被称为过拟合。

这种情况非常符合经验风险最小化原则，但是却不是理想的预测函数，这是经验风险最小化范式的一个问题。



<!--stackedit_data:
eyJoaXN0b3J5IjpbODY4OTE0NjEzLC0xNTE3NjI3Mjk2XX0=
-->